{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import & Install packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import gc\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import timm\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import cuml\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(torch.__version__)\n",
    "print(timm.__version__)"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:04.558569Z",
     "iopub.execute_input": "2022-12-11T20:14:04.559057Z",
     "iopub.status.idle": "2022-12-11T20:14:09.307043Z",
     "shell.execute_reply.started": "2022-12-11T20:14:04.558918Z",
     "shell.execute_reply": "2022-12-11T20:14:09.305964Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install ../input/openaiclipweights/python-ftfy-master/python-ftfy-master\n",
    "#!pip install ../input/openaiclipweights/clip/CLIP"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:09.309620Z",
     "iopub.execute_input": "2022-12-11T20:14:09.310607Z",
     "iopub.status.idle": "2022-12-11T20:14:09.315986Z",
     "shell.execute_reply.started": "2022-12-11T20:14:09.310564Z",
     "shell.execute_reply": "2022-12-11T20:14:09.314581Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python --version"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:09.317204Z",
     "iopub.execute_input": "2022-12-11T20:14:09.317743Z",
     "iopub.status.idle": "2022-12-11T20:14:10.277843Z",
     "shell.execute_reply.started": "2022-12-11T20:14:09.317705Z",
     "shell.execute_reply": "2022-12-11T20:14:10.276700Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Python 3.7.12\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('../input/petfinderdata/train-folds-1.csv')\n",
    "test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n",
    "sub = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\n",
    "\n",
    "train['path'] = train['Id'].map(lambda x: '../input/petfinder-pawpularity-score/train/' + x + '.jpg')\n",
    "test['path'] = test['Id'].map(lambda x: '../input/petfinder-pawpularity-score/test/' + x + '.jpg')\n",
    "\n",
    "# If its Public LB run, then augment Testset to chack batch size memory consumption.\n",
    "if test.shape[0] < 10:\n",
    "    test = pd.concat([\n",
    "        test, test, test, test, test,\n",
    "    ])\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "print(train.shape, test.shape, sub.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.279639Z",
     "iopub.execute_input": "2022-12-11T20:14:10.280353Z",
     "iopub.status.idle": "2022-12-11T20:14:10.400227Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.280307Z",
     "shell.execute_reply": "2022-12-11T20:14:10.398169Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "(9912, 18) (40, 14) (8, 2)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train['bins'] = (train['Pawpularity'] // 5).round()\n",
    "\n",
    "train['fold0'] = -1\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=1)\n",
    "for i, (_, test_index) in enumerate(skf.split(train.index, train['bins'])):\n",
    "    train.iloc[test_index, -1] = i\n",
    "\n",
    "train['fold0'] = train['fold0'].astype('int')\n",
    "gc.collect()\n",
    "\n",
    "train.groupby(['fold0'])['Pawpularity'].agg(['mean', 'std', 'count'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.403728Z",
     "iopub.execute_input": "2022-12-11T20:14:10.404658Z",
     "iopub.status.idle": "2022-12-11T20:14:10.706743Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.404621Z",
     "shell.execute_reply": "2022-12-11T20:14:10.705595Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            mean        std  count\nfold0                             \n0      38.044355  20.623269    496\n1      38.016129  20.599788    496\n2      38.018145  20.700209    496\n3      38.028226  20.665865    496\n4      38.026210  20.756338    496\n5      38.016129  20.668127    496\n6      38.070565  20.590600    496\n7      38.030242  20.731401    496\n8      38.125000  20.565454    496\n9      38.120968  20.697179    496\n10     38.064516  20.622334    496\n11     38.137097  20.657802    496\n12     37.941414  20.470741    495\n13     37.923232  20.480023    495\n14     37.991919  20.599908    495\n15     38.098990  20.593234    495\n16     37.995960  20.520454    495\n17     38.060606  20.500527    495\n18     38.014141  20.590125    495\n19     38.056566  20.596294    495",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>fold0</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>38.044355</td>\n      <td>20.623269</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.016129</td>\n      <td>20.599788</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38.018145</td>\n      <td>20.700209</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>38.028226</td>\n      <td>20.665865</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>38.026210</td>\n      <td>20.756338</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>38.016129</td>\n      <td>20.668127</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>38.070565</td>\n      <td>20.590600</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>38.030242</td>\n      <td>20.731401</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>38.125000</td>\n      <td>20.565454</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>38.120968</td>\n      <td>20.697179</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>38.064516</td>\n      <td>20.622334</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>38.137097</td>\n      <td>20.657802</td>\n      <td>496</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>37.941414</td>\n      <td>20.470741</td>\n      <td>495</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>37.923232</td>\n      <td>20.480023</td>\n      <td>495</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>37.991919</td>\n      <td>20.599908</td>\n      <td>495</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>38.098990</td>\n      <td>20.593234</td>\n      <td>495</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>37.995960</td>\n      <td>20.520454</td>\n      <td>495</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>38.060606</td>\n      <td>20.500527</td>\n      <td>495</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>38.014141</td>\n      <td>20.590125</td>\n      <td>495</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>38.056566</td>\n      <td>20.596294</td>\n      <td>495</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.708579Z",
     "iopub.execute_input": "2022-12-11T20:14:10.709053Z",
     "iopub.status.idle": "2022-12-11T20:14:10.731699Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.709014Z",
     "shell.execute_reply": "2022-12-11T20:14:10.730436Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n0  3ed899a8334a8e5c74f4a554f3ce6f08              0     1     1     1       0   \n1  e0a1efdaf4fbed8659b6d23994ee346e              0     1     1     1       0   \n2  6c159aede3df25fdbe781431aabcfc67              0     1     1     1       0   \n3  53b536999aecd800cfda720f3ca363cb              0     1     1     1       0   \n4  4e3c8816d95b083b870c6747a26fcb58              0     0     0     1       0   \n\n   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  fold  \\\n0          0      0        0      0          0     0     0            1     1   \n1          0      0        0      1          1     0     0            1     2   \n2          0      0        0      0          0     0     0            1     3   \n3          0      0        0      0          0     0     0            1     4   \n4          0      0        0      1          1     0     1            2     5   \n\n   dup                               nn0  \\\n0   -1  89a0b49aad4ce34c978b9a9c74cc95bd   \n1   -2  b89199007b4fbd51864eeaf8f264f946   \n2   -3  59b3e4a3c4fe0f1f56cb7741100e7a30   \n3   -4  0a05c55ca864b667d31c80ce2c68d6b3   \n4   -5  7af48bb7190c236d8876fe529b449c3f   \n\n                                                path  bins  fold0  \n0  ../input/petfinder-pawpularity-score/train/3ed...     0     17  \n1  ../input/petfinder-pawpularity-score/train/e0a...     0     14  \n2  ../input/petfinder-pawpularity-score/train/6c1...     0     15  \n3  ../input/petfinder-pawpularity-score/train/53b...     0     19  \n4  ../input/petfinder-pawpularity-score/train/4e3...     0      5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Subject Focus</th>\n      <th>Eyes</th>\n      <th>Face</th>\n      <th>Near</th>\n      <th>Action</th>\n      <th>Accessory</th>\n      <th>Group</th>\n      <th>Collage</th>\n      <th>Human</th>\n      <th>Occlusion</th>\n      <th>Info</th>\n      <th>Blur</th>\n      <th>Pawpularity</th>\n      <th>fold</th>\n      <th>dup</th>\n      <th>nn0</th>\n      <th>path</th>\n      <th>bins</th>\n      <th>fold0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3ed899a8334a8e5c74f4a554f3ce6f08</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>89a0b49aad4ce34c978b9a9c74cc95bd</td>\n      <td>../input/petfinder-pawpularity-score/train/3ed...</td>\n      <td>0</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e0a1efdaf4fbed8659b6d23994ee346e</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-2</td>\n      <td>b89199007b4fbd51864eeaf8f264f946</td>\n      <td>../input/petfinder-pawpularity-score/train/e0a...</td>\n      <td>0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6c159aede3df25fdbe781431aabcfc67</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-3</td>\n      <td>59b3e4a3c4fe0f1f56cb7741100e7a30</td>\n      <td>../input/petfinder-pawpularity-score/train/6c1...</td>\n      <td>0</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53b536999aecd800cfda720f3ca363cb</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-4</td>\n      <td>0a05c55ca864b667d31c80ce2c68d6b3</td>\n      <td>../input/petfinder-pawpularity-score/train/53b...</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4e3c8816d95b083b870c6747a26fcb58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>-5</td>\n      <td>7af48bb7190c236d8876fe529b449c3f</td>\n      <td>../input/petfinder-pawpularity-score/train/4e3...</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.733618Z",
     "iopub.execute_input": "2022-12-11T20:14:10.734276Z",
     "iopub.status.idle": "2022-12-11T20:14:10.754406Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.734240Z",
     "shell.execute_reply": "2022-12-11T20:14:10.753321Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "execution_count": 7,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n\n   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n0          1      1        0      0          1     0     1   \n1          0      1        1      0          0     0     0   \n2          1      1        1      0          1     1     1   \n3          0      0        0      0          0     1     0   \n4          1      0        1      0          1     1     0   \n\n                                                path  \n0  ../input/petfinder-pawpularity-score/test/4128...  \n1  ../input/petfinder-pawpularity-score/test/43a2...  \n2  ../input/petfinder-pawpularity-score/test/4e42...  \n3  ../input/petfinder-pawpularity-score/test/80bc...  \n4  ../input/petfinder-pawpularity-score/test/8f49...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Subject Focus</th>\n      <th>Eyes</th>\n      <th>Face</th>\n      <th>Near</th>\n      <th>Action</th>\n      <th>Accessory</th>\n      <th>Group</th>\n      <th>Collage</th>\n      <th>Human</th>\n      <th>Occlusion</th>\n      <th>Info</th>\n      <th>Blur</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4128bae22183829d2b5fea10effdb0c3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>../input/petfinder-pawpularity-score/test/4128...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43a2262d7738e3d420d453815151079e</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>../input/petfinder-pawpularity-score/test/43a2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4e429cead1848a298432a0acad014c9d</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>../input/petfinder-pawpularity-score/test/4e42...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>../input/petfinder-pawpularity-score/test/80bc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8f49844c382931444e68dffbe20228f4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>../input/petfinder-pawpularity-score/test/8f49...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# List Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "avail_pretrained_models = timm.list_models(pretrained=True)\n",
    "len(avail_pretrained_models), avail_pretrained_models"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.755852Z",
     "iopub.execute_input": "2022-12-11T20:14:10.756484Z",
     "iopub.status.idle": "2022-12-11T20:14:10.783974Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.756446Z",
     "shell.execute_reply": "2022-12-11T20:14:10.783103Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(709,\n ['adv_inception_v3',\n  'bat_resnext26ts',\n  'beit_base_patch16_224',\n  'beit_base_patch16_224_in22k',\n  'beit_base_patch16_384',\n  'beit_large_patch16_224',\n  'beit_large_patch16_224_in22k',\n  'beit_large_patch16_384',\n  'beit_large_patch16_512',\n  'botnet26t_256',\n  'cait_m36_384',\n  'cait_m48_448',\n  'cait_s24_224',\n  'cait_s24_384',\n  'cait_s36_384',\n  'cait_xs24_384',\n  'cait_xxs24_224',\n  'cait_xxs24_384',\n  'cait_xxs36_224',\n  'cait_xxs36_384',\n  'coat_lite_mini',\n  'coat_lite_small',\n  'coat_lite_tiny',\n  'coat_mini',\n  'coat_tiny',\n  'convit_base',\n  'convit_small',\n  'convit_tiny',\n  'convmixer_768_32',\n  'convmixer_1024_20_ks9_p14',\n  'convmixer_1536_20',\n  'convnext_base',\n  'convnext_base_384_in22ft1k',\n  'convnext_base_in22ft1k',\n  'convnext_base_in22k',\n  'convnext_large',\n  'convnext_large_384_in22ft1k',\n  'convnext_large_in22ft1k',\n  'convnext_large_in22k',\n  'convnext_small',\n  'convnext_small_384_in22ft1k',\n  'convnext_small_in22ft1k',\n  'convnext_small_in22k',\n  'convnext_tiny',\n  'convnext_tiny_384_in22ft1k',\n  'convnext_tiny_hnf',\n  'convnext_tiny_in22ft1k',\n  'convnext_tiny_in22k',\n  'convnext_xlarge_384_in22ft1k',\n  'convnext_xlarge_in22ft1k',\n  'convnext_xlarge_in22k',\n  'crossvit_9_240',\n  'crossvit_9_dagger_240',\n  'crossvit_15_240',\n  'crossvit_15_dagger_240',\n  'crossvit_15_dagger_408',\n  'crossvit_18_240',\n  'crossvit_18_dagger_240',\n  'crossvit_18_dagger_408',\n  'crossvit_base_240',\n  'crossvit_small_240',\n  'crossvit_tiny_240',\n  'cs3darknet_focus_l',\n  'cs3darknet_focus_m',\n  'cs3darknet_l',\n  'cs3darknet_m',\n  'cspdarknet53',\n  'cspresnet50',\n  'cspresnext50',\n  'darknet53',\n  'deit3_base_patch16_224',\n  'deit3_base_patch16_224_in21ft1k',\n  'deit3_base_patch16_384',\n  'deit3_base_patch16_384_in21ft1k',\n  'deit3_huge_patch14_224',\n  'deit3_huge_patch14_224_in21ft1k',\n  'deit3_large_patch16_224',\n  'deit3_large_patch16_224_in21ft1k',\n  'deit3_large_patch16_384',\n  'deit3_large_patch16_384_in21ft1k',\n  'deit3_small_patch16_224',\n  'deit3_small_patch16_224_in21ft1k',\n  'deit3_small_patch16_384',\n  'deit3_small_patch16_384_in21ft1k',\n  'deit_base_distilled_patch16_224',\n  'deit_base_distilled_patch16_384',\n  'deit_base_patch16_224',\n  'deit_base_patch16_384',\n  'deit_small_distilled_patch16_224',\n  'deit_small_patch16_224',\n  'deit_tiny_distilled_patch16_224',\n  'deit_tiny_patch16_224',\n  'densenet121',\n  'densenet161',\n  'densenet169',\n  'densenet201',\n  'densenetblur121d',\n  'dla34',\n  'dla46_c',\n  'dla46x_c',\n  'dla60',\n  'dla60_res2net',\n  'dla60_res2next',\n  'dla60x',\n  'dla60x_c',\n  'dla102',\n  'dla102x',\n  'dla102x2',\n  'dla169',\n  'dm_nfnet_f0',\n  'dm_nfnet_f1',\n  'dm_nfnet_f2',\n  'dm_nfnet_f3',\n  'dm_nfnet_f4',\n  'dm_nfnet_f5',\n  'dm_nfnet_f6',\n  'dpn68',\n  'dpn68b',\n  'dpn92',\n  'dpn98',\n  'dpn107',\n  'dpn131',\n  'eca_botnext26ts_256',\n  'eca_halonext26ts',\n  'eca_nfnet_l0',\n  'eca_nfnet_l1',\n  'eca_nfnet_l2',\n  'eca_resnet33ts',\n  'eca_resnext26ts',\n  'ecaresnet26t',\n  'ecaresnet50d',\n  'ecaresnet50d_pruned',\n  'ecaresnet50t',\n  'ecaresnet101d',\n  'ecaresnet101d_pruned',\n  'ecaresnet269d',\n  'ecaresnetlight',\n  'edgenext_small',\n  'edgenext_small_rw',\n  'edgenext_x_small',\n  'edgenext_xx_small',\n  'efficientnet_b0',\n  'efficientnet_b1',\n  'efficientnet_b1_pruned',\n  'efficientnet_b2',\n  'efficientnet_b2_pruned',\n  'efficientnet_b3',\n  'efficientnet_b3_pruned',\n  'efficientnet_b4',\n  'efficientnet_el',\n  'efficientnet_el_pruned',\n  'efficientnet_em',\n  'efficientnet_es',\n  'efficientnet_es_pruned',\n  'efficientnet_lite0',\n  'efficientnetv2_rw_m',\n  'efficientnetv2_rw_s',\n  'efficientnetv2_rw_t',\n  'ens_adv_inception_resnet_v2',\n  'ese_vovnet19b_dw',\n  'ese_vovnet39b',\n  'fbnetc_100',\n  'fbnetv3_b',\n  'fbnetv3_d',\n  'fbnetv3_g',\n  'gc_efficientnetv2_rw_t',\n  'gcresnet33ts',\n  'gcresnet50t',\n  'gcresnext26ts',\n  'gcresnext50ts',\n  'gernet_l',\n  'gernet_m',\n  'gernet_s',\n  'ghostnet_100',\n  'gluon_inception_v3',\n  'gluon_resnet18_v1b',\n  'gluon_resnet34_v1b',\n  'gluon_resnet50_v1b',\n  'gluon_resnet50_v1c',\n  'gluon_resnet50_v1d',\n  'gluon_resnet50_v1s',\n  'gluon_resnet101_v1b',\n  'gluon_resnet101_v1c',\n  'gluon_resnet101_v1d',\n  'gluon_resnet101_v1s',\n  'gluon_resnet152_v1b',\n  'gluon_resnet152_v1c',\n  'gluon_resnet152_v1d',\n  'gluon_resnet152_v1s',\n  'gluon_resnext50_32x4d',\n  'gluon_resnext101_32x4d',\n  'gluon_resnext101_64x4d',\n  'gluon_senet154',\n  'gluon_seresnext50_32x4d',\n  'gluon_seresnext101_32x4d',\n  'gluon_seresnext101_64x4d',\n  'gluon_xception65',\n  'gmixer_24_224',\n  'gmlp_s16_224',\n  'halo2botnet50ts_256',\n  'halonet26t',\n  'halonet50ts',\n  'haloregnetz_b',\n  'hardcorenas_a',\n  'hardcorenas_b',\n  'hardcorenas_c',\n  'hardcorenas_d',\n  'hardcorenas_e',\n  'hardcorenas_f',\n  'hrnet_w18',\n  'hrnet_w18_small',\n  'hrnet_w18_small_v2',\n  'hrnet_w30',\n  'hrnet_w32',\n  'hrnet_w40',\n  'hrnet_w44',\n  'hrnet_w48',\n  'hrnet_w64',\n  'ig_resnext101_32x8d',\n  'ig_resnext101_32x16d',\n  'ig_resnext101_32x32d',\n  'ig_resnext101_32x48d',\n  'inception_resnet_v2',\n  'inception_v3',\n  'inception_v4',\n  'jx_nest_base',\n  'jx_nest_small',\n  'jx_nest_tiny',\n  'lambda_resnet26rpt_256',\n  'lambda_resnet26t',\n  'lambda_resnet50ts',\n  'lamhalobotnet50ts_256',\n  'lcnet_050',\n  'lcnet_075',\n  'lcnet_100',\n  'legacy_senet154',\n  'legacy_seresnet18',\n  'legacy_seresnet34',\n  'legacy_seresnet50',\n  'legacy_seresnet101',\n  'legacy_seresnet152',\n  'legacy_seresnext26_32x4d',\n  'legacy_seresnext50_32x4d',\n  'legacy_seresnext101_32x4d',\n  'levit_128',\n  'levit_128s',\n  'levit_192',\n  'levit_256',\n  'levit_384',\n  'mixer_b16_224',\n  'mixer_b16_224_in21k',\n  'mixer_b16_224_miil',\n  'mixer_b16_224_miil_in21k',\n  'mixer_l16_224',\n  'mixer_l16_224_in21k',\n  'mixnet_l',\n  'mixnet_m',\n  'mixnet_s',\n  'mixnet_xl',\n  'mnasnet_100',\n  'mnasnet_small',\n  'mobilenetv2_050',\n  'mobilenetv2_100',\n  'mobilenetv2_110d',\n  'mobilenetv2_120d',\n  'mobilenetv2_140',\n  'mobilenetv3_large_100',\n  'mobilenetv3_large_100_miil',\n  'mobilenetv3_large_100_miil_in21k',\n  'mobilenetv3_rw',\n  'mobilenetv3_small_050',\n  'mobilenetv3_small_075',\n  'mobilenetv3_small_100',\n  'mobilevit_s',\n  'mobilevit_xs',\n  'mobilevit_xxs',\n  'mobilevitv2_050',\n  'mobilevitv2_075',\n  'mobilevitv2_100',\n  'mobilevitv2_125',\n  'mobilevitv2_150',\n  'mobilevitv2_150_384_in22ft1k',\n  'mobilevitv2_150_in22ft1k',\n  'mobilevitv2_175',\n  'mobilevitv2_175_384_in22ft1k',\n  'mobilevitv2_175_in22ft1k',\n  'mobilevitv2_200',\n  'mobilevitv2_200_384_in22ft1k',\n  'mobilevitv2_200_in22ft1k',\n  'nasnetalarge',\n  'nf_regnet_b1',\n  'nf_resnet50',\n  'nfnet_l0',\n  'pit_b_224',\n  'pit_b_distilled_224',\n  'pit_s_224',\n  'pit_s_distilled_224',\n  'pit_ti_224',\n  'pit_ti_distilled_224',\n  'pit_xs_224',\n  'pit_xs_distilled_224',\n  'pnasnet5large',\n  'poolformer_m36',\n  'poolformer_m48',\n  'poolformer_s12',\n  'poolformer_s24',\n  'poolformer_s36',\n  'regnetv_040',\n  'regnetv_064',\n  'regnetx_002',\n  'regnetx_004',\n  'regnetx_006',\n  'regnetx_008',\n  'regnetx_016',\n  'regnetx_032',\n  'regnetx_040',\n  'regnetx_064',\n  'regnetx_080',\n  'regnetx_120',\n  'regnetx_160',\n  'regnetx_320',\n  'regnety_002',\n  'regnety_004',\n  'regnety_006',\n  'regnety_008',\n  'regnety_016',\n  'regnety_032',\n  'regnety_040',\n  'regnety_064',\n  'regnety_080',\n  'regnety_120',\n  'regnety_160',\n  'regnety_320',\n  'regnetz_040',\n  'regnetz_040h',\n  'regnetz_b16',\n  'regnetz_c16',\n  'regnetz_c16_evos',\n  'regnetz_d8',\n  'regnetz_d8_evos',\n  'regnetz_d32',\n  'regnetz_e8',\n  'repvgg_a2',\n  'repvgg_b0',\n  'repvgg_b1',\n  'repvgg_b1g4',\n  'repvgg_b2',\n  'repvgg_b2g4',\n  'repvgg_b3',\n  'repvgg_b3g4',\n  'res2net50_14w_8s',\n  'res2net50_26w_4s',\n  'res2net50_26w_6s',\n  'res2net50_26w_8s',\n  'res2net50_48w_2s',\n  'res2net101_26w_4s',\n  'res2next50',\n  'resmlp_12_224',\n  'resmlp_12_224_dino',\n  'resmlp_12_distilled_224',\n  'resmlp_24_224',\n  'resmlp_24_224_dino',\n  'resmlp_24_distilled_224',\n  'resmlp_36_224',\n  'resmlp_36_distilled_224',\n  'resmlp_big_24_224',\n  'resmlp_big_24_224_in22ft1k',\n  'resmlp_big_24_distilled_224',\n  'resnest14d',\n  'resnest26d',\n  'resnest50d',\n  'resnest50d_1s4x24d',\n  'resnest50d_4s2x40d',\n  'resnest101e',\n  'resnest200e',\n  'resnest269e',\n  'resnet10t',\n  'resnet14t',\n  'resnet18',\n  'resnet18d',\n  'resnet26',\n  'resnet26d',\n  'resnet26t',\n  'resnet32ts',\n  'resnet33ts',\n  'resnet34',\n  'resnet34d',\n  'resnet50',\n  'resnet50_gn',\n  'resnet50d',\n  'resnet51q',\n  'resnet61q',\n  'resnet101',\n  'resnet101d',\n  'resnet152',\n  'resnet152d',\n  'resnet200d',\n  'resnetaa50',\n  'resnetblur50',\n  'resnetrs50',\n  'resnetrs101',\n  'resnetrs152',\n  'resnetrs200',\n  'resnetrs270',\n  'resnetrs350',\n  'resnetrs420',\n  'resnetv2_50',\n  'resnetv2_50d_evos',\n  'resnetv2_50d_gn',\n  'resnetv2_50x1_bit_distilled',\n  'resnetv2_50x1_bitm',\n  'resnetv2_50x1_bitm_in21k',\n  'resnetv2_50x3_bitm',\n  'resnetv2_50x3_bitm_in21k',\n  'resnetv2_101',\n  'resnetv2_101x1_bitm',\n  'resnetv2_101x1_bitm_in21k',\n  'resnetv2_101x3_bitm',\n  'resnetv2_101x3_bitm_in21k',\n  'resnetv2_152x2_bit_teacher',\n  'resnetv2_152x2_bit_teacher_384',\n  'resnetv2_152x2_bitm',\n  'resnetv2_152x2_bitm_in21k',\n  'resnetv2_152x4_bitm',\n  'resnetv2_152x4_bitm_in21k',\n  'resnext26ts',\n  'resnext50_32x4d',\n  'resnext50d_32x4d',\n  'resnext101_32x8d',\n  'resnext101_64x4d',\n  'rexnet_100',\n  'rexnet_130',\n  'rexnet_150',\n  'rexnet_200',\n  'sebotnet33ts_256',\n  'sehalonet33ts',\n  'selecsls42b',\n  'selecsls60',\n  'selecsls60b',\n  'semnasnet_075',\n  'semnasnet_100',\n  'sequencer2d_l',\n  'sequencer2d_m',\n  'sequencer2d_s',\n  'seresnet33ts',\n  'seresnet50',\n  'seresnet152d',\n  'seresnext26d_32x4d',\n  'seresnext26t_32x4d',\n  'seresnext26ts',\n  'seresnext50_32x4d',\n  'seresnext101_32x8d',\n  'seresnext101d_32x8d',\n  'seresnextaa101d_32x8d',\n  'skresnet18',\n  'skresnet34',\n  'skresnext50_32x4d',\n  'spnasnet_100',\n  'ssl_resnet18',\n  'ssl_resnet50',\n  'ssl_resnext50_32x4d',\n  'ssl_resnext101_32x4d',\n  'ssl_resnext101_32x8d',\n  'ssl_resnext101_32x16d',\n  'swin_base_patch4_window7_224',\n  'swin_base_patch4_window7_224_in22k',\n  'swin_base_patch4_window12_384',\n  'swin_base_patch4_window12_384_in22k',\n  'swin_large_patch4_window7_224',\n  'swin_large_patch4_window7_224_in22k',\n  'swin_large_patch4_window12_384',\n  'swin_large_patch4_window12_384_in22k',\n  'swin_s3_base_224',\n  'swin_s3_small_224',\n  'swin_s3_tiny_224',\n  'swin_small_patch4_window7_224',\n  'swin_tiny_patch4_window7_224',\n  'swinv2_base_window8_256',\n  'swinv2_base_window12_192_22k',\n  'swinv2_base_window12to16_192to256_22kft1k',\n  'swinv2_base_window12to24_192to384_22kft1k',\n  'swinv2_base_window16_256',\n  'swinv2_cr_small_224',\n  'swinv2_cr_small_ns_224',\n  'swinv2_cr_tiny_ns_224',\n  'swinv2_large_window12_192_22k',\n  'swinv2_large_window12to16_192to256_22kft1k',\n  'swinv2_large_window12to24_192to384_22kft1k',\n  'swinv2_small_window8_256',\n  'swinv2_small_window16_256',\n  'swinv2_tiny_window8_256',\n  'swinv2_tiny_window16_256',\n  'swsl_resnet18',\n  'swsl_resnet50',\n  'swsl_resnext50_32x4d',\n  'swsl_resnext101_32x4d',\n  'swsl_resnext101_32x8d',\n  'swsl_resnext101_32x16d',\n  'tf_efficientnet_b0',\n  'tf_efficientnet_b0_ap',\n  'tf_efficientnet_b0_ns',\n  'tf_efficientnet_b1',\n  'tf_efficientnet_b1_ap',\n  'tf_efficientnet_b1_ns',\n  'tf_efficientnet_b2',\n  'tf_efficientnet_b2_ap',\n  'tf_efficientnet_b2_ns',\n  'tf_efficientnet_b3',\n  'tf_efficientnet_b3_ap',\n  'tf_efficientnet_b3_ns',\n  'tf_efficientnet_b4',\n  'tf_efficientnet_b4_ap',\n  'tf_efficientnet_b4_ns',\n  'tf_efficientnet_b5',\n  'tf_efficientnet_b5_ap',\n  'tf_efficientnet_b5_ns',\n  'tf_efficientnet_b6',\n  'tf_efficientnet_b6_ap',\n  'tf_efficientnet_b6_ns',\n  'tf_efficientnet_b7',\n  'tf_efficientnet_b7_ap',\n  'tf_efficientnet_b7_ns',\n  'tf_efficientnet_b8',\n  'tf_efficientnet_b8_ap',\n  'tf_efficientnet_cc_b0_4e',\n  'tf_efficientnet_cc_b0_8e',\n  'tf_efficientnet_cc_b1_8e',\n  'tf_efficientnet_el',\n  'tf_efficientnet_em',\n  'tf_efficientnet_es',\n  'tf_efficientnet_l2_ns',\n  'tf_efficientnet_l2_ns_475',\n  'tf_efficientnet_lite0',\n  'tf_efficientnet_lite1',\n  'tf_efficientnet_lite2',\n  'tf_efficientnet_lite3',\n  'tf_efficientnet_lite4',\n  'tf_efficientnetv2_b0',\n  'tf_efficientnetv2_b1',\n  'tf_efficientnetv2_b2',\n  'tf_efficientnetv2_b3',\n  'tf_efficientnetv2_l',\n  'tf_efficientnetv2_l_in21ft1k',\n  'tf_efficientnetv2_l_in21k',\n  'tf_efficientnetv2_m',\n  'tf_efficientnetv2_m_in21ft1k',\n  'tf_efficientnetv2_m_in21k',\n  'tf_efficientnetv2_s',\n  'tf_efficientnetv2_s_in21ft1k',\n  'tf_efficientnetv2_s_in21k',\n  'tf_efficientnetv2_xl_in21ft1k',\n  'tf_efficientnetv2_xl_in21k',\n  'tf_inception_v3',\n  'tf_mixnet_l',\n  'tf_mixnet_m',\n  'tf_mixnet_s',\n  'tf_mobilenetv3_large_075',\n  'tf_mobilenetv3_large_100',\n  'tf_mobilenetv3_large_minimal_100',\n  'tf_mobilenetv3_small_075',\n  'tf_mobilenetv3_small_100',\n  'tf_mobilenetv3_small_minimal_100',\n  'tinynet_a',\n  'tinynet_b',\n  'tinynet_c',\n  'tinynet_d',\n  'tinynet_e',\n  'tnt_s_patch16_224',\n  'tresnet_l',\n  'tresnet_l_448',\n  'tresnet_m',\n  'tresnet_m_448',\n  'tresnet_m_miil_in21k',\n  'tresnet_xl',\n  'tresnet_xl_448',\n  'tv_densenet121',\n  'tv_resnet34',\n  'tv_resnet50',\n  'tv_resnet101',\n  'tv_resnet152',\n  'tv_resnext50_32x4d',\n  'twins_pcpvt_base',\n  'twins_pcpvt_large',\n  'twins_pcpvt_small',\n  'twins_svt_base',\n  'twins_svt_large',\n  'twins_svt_small',\n  'vgg11',\n  'vgg11_bn',\n  'vgg13',\n  'vgg13_bn',\n  'vgg16',\n  'vgg16_bn',\n  'vgg19',\n  'vgg19_bn',\n  'visformer_small',\n  'vit_base_patch8_224',\n  'vit_base_patch8_224_dino',\n  'vit_base_patch8_224_in21k',\n  'vit_base_patch16_224',\n  'vit_base_patch16_224_dino',\n  'vit_base_patch16_224_in21k',\n  'vit_base_patch16_224_miil',\n  'vit_base_patch16_224_miil_in21k',\n  'vit_base_patch16_224_sam',\n  'vit_base_patch16_384',\n  'vit_base_patch16_rpn_224',\n  'vit_base_patch32_224',\n  'vit_base_patch32_224_in21k',\n  'vit_base_patch32_224_sam',\n  'vit_base_patch32_384',\n  'vit_base_r50_s16_224_in21k',\n  'vit_base_r50_s16_384',\n  'vit_huge_patch14_224_in21k',\n  'vit_large_patch16_224',\n  'vit_large_patch16_224_in21k',\n  'vit_large_patch16_384',\n  'vit_large_patch32_224_in21k',\n  'vit_large_patch32_384',\n  'vit_large_r50_s32_224',\n  'vit_large_r50_s32_224_in21k',\n  'vit_large_r50_s32_384',\n  'vit_relpos_base_patch16_224',\n  'vit_relpos_base_patch16_clsgap_224',\n  'vit_relpos_base_patch32_plus_rpn_256',\n  'vit_relpos_medium_patch16_224',\n  'vit_relpos_medium_patch16_cls_224',\n  'vit_relpos_medium_patch16_rpn_224',\n  'vit_relpos_small_patch16_224',\n  'vit_small_patch8_224_dino',\n  'vit_small_patch16_224',\n  'vit_small_patch16_224_dino',\n  'vit_small_patch16_224_in21k',\n  'vit_small_patch16_384',\n  'vit_small_patch32_224',\n  'vit_small_patch32_224_in21k',\n  'vit_small_patch32_384',\n  'vit_small_r26_s32_224',\n  'vit_small_r26_s32_224_in21k',\n  'vit_small_r26_s32_384',\n  'vit_srelpos_medium_patch16_224',\n  'vit_srelpos_small_patch16_224',\n  'vit_tiny_patch16_224',\n  'vit_tiny_patch16_224_in21k',\n  'vit_tiny_patch16_384',\n  'vit_tiny_r_s16_p8_224',\n  'vit_tiny_r_s16_p8_224_in21k',\n  'vit_tiny_r_s16_p8_384',\n  'volo_d1_224',\n  'volo_d1_384',\n  'volo_d2_224',\n  'volo_d2_384',\n  'volo_d3_224',\n  'volo_d3_448',\n  'volo_d4_224',\n  'volo_d4_448',\n  'volo_d5_224',\n  'volo_d5_448',\n  'volo_d5_512',\n  'wide_resnet50_2',\n  'wide_resnet101_2',\n  'xception',\n  'xception41',\n  'xception41p',\n  'xception65',\n  'xception65p',\n  'xception71',\n  'xcit_large_24_p8_224',\n  'xcit_large_24_p8_224_dist',\n  'xcit_large_24_p8_384_dist',\n  'xcit_large_24_p16_224',\n  'xcit_large_24_p16_224_dist',\n  'xcit_large_24_p16_384_dist',\n  'xcit_medium_24_p8_224',\n  'xcit_medium_24_p8_224_dist',\n  'xcit_medium_24_p8_384_dist',\n  'xcit_medium_24_p16_224',\n  'xcit_medium_24_p16_224_dist',\n  'xcit_medium_24_p16_384_dist',\n  'xcit_nano_12_p8_224',\n  'xcit_nano_12_p8_224_dist',\n  'xcit_nano_12_p8_384_dist',\n  'xcit_nano_12_p16_224',\n  'xcit_nano_12_p16_224_dist',\n  'xcit_nano_12_p16_384_dist',\n  'xcit_small_12_p8_224',\n  'xcit_small_12_p8_224_dist',\n  'xcit_small_12_p8_384_dist',\n  'xcit_small_12_p16_224',\n  'xcit_small_12_p16_224_dist',\n  'xcit_small_12_p16_384_dist',\n  'xcit_small_24_p8_224',\n  'xcit_small_24_p8_224_dist',\n  'xcit_small_24_p8_384_dist',\n  'xcit_small_24_p16_224',\n  'xcit_small_24_p16_224_dist',\n  'xcit_small_24_p16_384_dist',\n  'xcit_tiny_12_p8_224',\n  'xcit_tiny_12_p8_224_dist',\n  'xcit_tiny_12_p8_384_dist',\n  'xcit_tiny_12_p16_224',\n  'xcit_tiny_12_p16_224_dist',\n  'xcit_tiny_12_p16_384_dist',\n  'xcit_tiny_24_p8_224',\n  'xcit_tiny_24_p8_224_dist',\n  'xcit_tiny_24_p8_384_dist',\n  'xcit_tiny_24_p16_224',\n  'xcit_tiny_24_p16_224_dist',\n  'xcit_tiny_24_p16_384_dist'])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Here we have listed all 575 pretrained model architectures available in timm library.\n",
    "\n",
    "#### The first part of the solution is extracting the features from the last layer of listed models and run a SVR on the extracted features. \n",
    "\n",
    "#### Majority of the models are trained using 1000 classes in imagenet, which is why the output shae is 1000 for each model.\n",
    "\n",
    "#### Idea is to find the subset od models (from 575) which has a good RMSE.\n",
    "\n",
    "#### Forward models selection algorithm, followed by RMSE hill climbing logic was used. Starting with one model, and then keep adding until the RMSE stops incresing. \n",
    "\n",
    "#### The pretrained models found by the forward model selection alogirthm used in this solution is listed below. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "names = [\n",
    "    'deit_base_distilled_patch16_384',\n",
    "    'fbnetc_100',\n",
    "    'ig_resnext101_32x8d',\n",
    "    'ig_resnext101_32x48d',\n",
    "    'repvgg_b0',\n",
    "    'resnetv2_152x4_bitm',\n",
    "    'rexnet_200',\n",
    "    'resnest269e',\n",
    "    'swsl_resnext101_32x8d',\n",
    "    'tf_efficientnet_b6_ns',\n",
    "    'tf_efficientnet_b7_ns',\n",
    "    'tf_efficientnet_b8_ap',\n",
    "    'tf_efficientnet_l2_ns_475',\n",
    "    'vit_base_patch16_384',\n",
    "    'vit_large_patch16_384',\n",
    "    'vit_large_r50_s32_384',\n",
    "]\n",
    "\n",
    "names_hflip_crop = [\n",
    "    'tf_efficientnet_l2_ns_hflip_384',\n",
    "    'deit_base_distilled_patch16_384_hflip_384',\n",
    "    'ig_resnext101_32x48d_hflip_384',\n",
    "    'tf_efficientnet_l2_ns_512',\n",
    "]\n",
    "\n",
    "names_orig = [\n",
    "    'ig_resnext101_32x48d',\n",
    "    'vit_large_r50_s32_384'\n",
    "]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.785399Z",
     "iopub.execute_input": "2022-12-11T20:14:10.785963Z",
     "iopub.status.idle": "2022-12-11T20:14:10.792228Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.785928Z",
     "shell.execute_reply": "2022-12-11T20:14:10.791307Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dictionary with the path to all pretrained weights available in Kaggle datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "modelpath = {m.split('/')[-1].split('.')[0]: m for m in\n",
    "             glob('../input/pytorch-pretrained-0/*.pt') + glob('../input/pytorch-pretrained-1/*.pt') + glob(\n",
    "                 '../input/pytorch-pretrained-2/*.pt') + glob('../input/pytorch-pretrained-3/*.pt')}\n",
    "modelpath"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.793899Z",
     "iopub.execute_input": "2022-12-11T20:14:10.794812Z",
     "iopub.status.idle": "2022-12-11T20:14:10.826317Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.794775Z",
     "shell.execute_reply": "2022-12-11T20:14:10.825509Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "execution_count": 10,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'resnetv2_101x1_bitm': '../input/pytorch-pretrained-0/resnetv2_101x1_bitm.pt',\n 'xcit_large_24_p8_384_dist': '../input/pytorch-pretrained-0/xcit_large_24_p8_384_dist.pt',\n 'tf_efficientnet_l2_ns_475': '../input/pytorch-pretrained-0/tf_efficientnet_l2_ns_475.pt',\n 'swsl_resnext101_32x8d': '../input/pytorch-pretrained-0/swsl_resnext101_32x8d.pt',\n 'ig_resnext101_32x48d': '../input/pytorch-pretrained-0/ig_resnext101_32x48d.pt',\n 'ig_resnext101_32x8d': '../input/pytorch-pretrained-0/ig_resnext101_32x8d.pt',\n 'vit_large_r50_s32_384': '../input/pytorch-pretrained-0/vit_large_r50_s32_384.pt',\n 'vit_base_patch16_384': '../input/pytorch-pretrained-0/vit_base_patch16_384.pt',\n 'deit_base_distilled_patch16_384': '../input/pytorch-pretrained-0/deit_base_distilled_patch16_384.pt',\n 'beit_large_patch16_512': '../input/pytorch-pretrained-0/beit_large_patch16_512.pt',\n 'rexnet_200': '../input/pytorch-pretrained-1/rexnet_200.pt',\n 'resmlp_big_24_224_in22ft1k': '../input/pytorch-pretrained-1/resmlp_big_24_224_in22ft1k.pt',\n 'swin_large_patch4_window12_384': '../input/pytorch-pretrained-1/swin_large_patch4_window12_384.pt',\n 'resnext50_32x4d': '../input/pytorch-pretrained-1/resnext50_32x4d.pt',\n 'cait_m36_384': '../input/pytorch-pretrained-1/cait_m36_384.pt',\n 'twins_pcpvt_small': '../input/pytorch-pretrained-1/twins_pcpvt_small.pt',\n 'pit_ti_distilled_224': '../input/pytorch-pretrained-1/pit_ti_distilled_224.pt',\n 'beit_large_patch16_224': '../input/pytorch-pretrained-1/beit_large_patch16_224.pt',\n 'repvgg_b0': '../input/pytorch-pretrained-1/repvgg_b0.pt',\n 'vit_large_patch16_384': '../input/pytorch-pretrained-1/vit_large_patch16_384.pt',\n 'tf_efficientnetv2_l_in21ft1k': '../input/pytorch-pretrained-1/tf_efficientnetv2_l_in21ft1k.pt',\n 'vit_large_patch16_224': '../input/pytorch-pretrained-1/vit_large_patch16_224.pt',\n 'swsl_resnext101_32x4d': '../input/pytorch-pretrained-1/swsl_resnext101_32x4d.pt',\n 'tf_efficientnet_l2_ns': '../input/pytorch-pretrained-1/tf_efficientnet_l2_ns.pt',\n 'dm_nfnet_f2': '../input/pytorch-pretrained-1/dm_nfnet_f2.pt',\n 'resnest200e': '../input/pytorch-pretrained-1/resnest200e.pt',\n 'resnetv2_152x4_bitm': '../input/pytorch-pretrained-2/resnetv2_152x4_bitm.pt',\n 'fbnetc_100': '../input/pytorch-pretrained-2/fbnetc_100.pt',\n 'tf_efficientnet_b7_ns': '../input/pytorch-pretrained-2/tf_efficientnet_b7_ns.pt',\n 'resnest269e': '../input/pytorch-pretrained-2/resnest269e.pt',\n 'vit_base_resnet50_384': '../input/pytorch-pretrained-2/vit_base_resnet50_384.pt',\n 'regnetz_e8': '../input/pytorch-pretrained-2/regnetz_e8.pt',\n 'cait_m48_448': '../input/pytorch-pretrained-2/cait_m48_448.pt',\n 'rexnet_130': '../input/pytorch-pretrained-2/rexnet_130.pt',\n 'dm_nfnet_f6': '../input/pytorch-pretrained-2/dm_nfnet_f6.pt',\n 'dla34': '../input/pytorch-pretrained-2/dla34.pt',\n 'sebotnet33ts_256': '../input/pytorch-pretrained-2/sebotnet33ts_256.pt',\n 'tf_efficientnet_b8_ap': '../input/pytorch-pretrained-2/tf_efficientnet_b8_ap.pt',\n 'tf_efficientnetv2_xl_in21ft1k': '../input/pytorch-pretrained-2/tf_efficientnetv2_xl_in21ft1k.pt',\n 'tf_efficientnet_b6_ns': '../input/pytorch-pretrained-2/tf_efficientnet_b6_ns.pt',\n 'vit_base_patch16_sam_224': '../input/pytorch-pretrained-3/vit_base_patch16_sam_224.pt',\n 'vit_small_patch16_384': '../input/pytorch-pretrained-3/vit_small_patch16_384.pt',\n 'vit_small_patch32_384': '../input/pytorch-pretrained-3/vit_small_patch32_384.pt',\n 'vit_base_patch16_224': '../input/pytorch-pretrained-3/vit_base_patch16_224.pt',\n 'vit_small_patch16_224': '../input/pytorch-pretrained-3/vit_small_patch16_224.pt'}"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extracting the TESTSET features from each imagenet pretrained model and append to a dictionary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class PawpularDataset:\n",
    "    def __init__(self, images, base_path='../input/petfinder-pawpularity-score/train/', modelcfg=None, aug=0):\n",
    "        self.images = images.copy()\n",
    "        self.base_path = base_path\n",
    "        self.transform = create_transform(**modelcfg)\n",
    "        self.aug = aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.base_path + self.images[item] + '.jpg').convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "EMB_TEST = {}\n",
    "for arch in names:\n",
    "    starttime = time.time()\n",
    "\n",
    "    model = timm.create_model(arch, pretrained=False).to('cuda')\n",
    "    model.load_state_dict(torch.load(modelpath[arch]))\n",
    "    model.eval()\n",
    "\n",
    "    train_dataset = PawpularDataset(\n",
    "        images=test.Id.values,\n",
    "        base_path='../input/petfinder-pawpularity-score/test/',\n",
    "        modelcfg=resolve_data_config({}, model=model),\n",
    "        aug=0,\n",
    "    )\n",
    "    BS = 10 if arch in ['tf_efficientnet_l2_ns'] else 16\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=2, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        res = [model(img.to('cuda')).cpu().numpy() for img in train_dataloader]\n",
    "    res = np.concatenate(res, 0)\n",
    "    EMB_TEST[arch] = res\n",
    "\n",
    "    print(arch, ', Done in:', int(time.time() - starttime), 's')\n",
    "\n",
    "    del model, res\n",
    "    torch.cuda.empty_cache()  # PyTorch thing to clean RAM\n",
    "    gc.collect()\n",
    "\n",
    "print(time.time())\n",
    "len(EMB_TEST), EMB_TEST.keys()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:14:10.827653Z",
     "iopub.execute_input": "2022-12-11T20:14:10.828210Z",
     "iopub.status.idle": "2022-12-11T20:19:22.875939Z",
     "shell.execute_reply.started": "2022-12-11T20:14:10.828174Z",
     "shell.execute_reply": "2022-12-11T20:19:22.874751Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": "deit_base_distilled_patch16_384 , Done in: 20 s\nfbnetc_100 , Done in: 1 s\nig_resnext101_32x8d , Done in: 6 s\nig_resnext101_32x48d , Done in: 57 s\nrepvgg_b0 , Done in: 1 s\nresnetv2_152x4_bitm , Done in: 69 s\nrexnet_200 , Done in: 2 s\nresnest269e , Done in: 12 s\nswsl_resnext101_32x8d , Done in: 7 s\ntf_efficientnet_b6_ns , Done in: 4 s\ntf_efficientnet_b7_ns , Done in: 7 s\ntf_efficientnet_b8_ap , Done in: 10 s\ntf_efficientnet_l2_ns_475 , Done in: 40 s\nvit_base_patch16_384 , Done in: 8 s\nvit_large_patch16_384 , Done in: 27 s\nvit_large_r50_s32_384 , Done in: 27 s\n1670789962.867323\n",
     "output_type": "stream"
    },
    {
     "execution_count": 11,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(16,\n dict_keys(['deit_base_distilled_patch16_384', 'fbnetc_100', 'ig_resnext101_32x8d', 'ig_resnext101_32x48d', 'repvgg_b0', 'resnetv2_152x4_bitm', 'rexnet_200', 'resnest269e', 'swsl_resnext101_32x8d', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8_ap', 'tf_efficientnet_l2_ns_475', 'vit_base_patch16_384', 'vit_large_patch16_384', 'vit_large_r50_s32_384']))"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "EMB_TEST[\"deit_base_distilled_patch16_384\"].shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:19:22.877726Z",
     "iopub.execute_input": "2022-12-11T20:19:22.878132Z",
     "iopub.status.idle": "2022-12-11T20:19:22.885408Z",
     "shell.execute_reply.started": "2022-12-11T20:19:22.878092Z",
     "shell.execute_reply": "2022-12-11T20:19:22.884289Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "execution_count": 12,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(40, 1000)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We have 40 images in the test set, and 1000 classes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extracting features using Horizontal Flip and small crop. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class PawpularDataset_HFLIP:\n",
    "    def __init__(self, images, base_path='../input/petfinder-pawpularity-score/train/', modelcfg=None, doflip=False):\n",
    "        self.images = images.copy()\n",
    "        self.base_path = base_path\n",
    "        self.transform = modelcfg\n",
    "        self.doflip = doflip\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.base_path + self.images[item] + '.jpg').convert('RGB')\n",
    "\n",
    "        if self.doflip == True:\n",
    "            img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "            width, height = img.size\n",
    "            img = img.crop((0.0 * width, 0.02 * height, 0.98 * width, 0.98 * height))\n",
    "\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "for arch in names_hflip_crop:\n",
    "    starttime = time.time()\n",
    "\n",
    "    archname = arch.split('_hflip_')[0]\n",
    "    if arch == 'tf_efficientnet_l2_ns_512':\n",
    "        archname = 'tf_efficientnet_l2_ns'\n",
    "    model = timm.create_model(archname, pretrained=False).to('cuda')\n",
    "    model.load_state_dict(torch.load(modelpath[archname]))\n",
    "    model.eval()\n",
    "\n",
    "    # Get model default transforms\n",
    "    transf = resolve_data_config({}, model=model)\n",
    "    sz = int(arch.split('_')[-1])\n",
    "    transf['input_size'] = (3, sz, sz)\n",
    "    transf['crop_pct'] = 1.0\n",
    "    transf = create_transform(**transf)\n",
    "\n",
    "    doflip = True if arch.split('_')[-2] == 'hflip' else False\n",
    "    train_dataset = PawpularDataset_HFLIP(\n",
    "        images=test.Id.values,\n",
    "        base_path='../input/petfinder-pawpularity-score/test/',\n",
    "        modelcfg=transf,\n",
    "        doflip=doflip,\n",
    "    )\n",
    "\n",
    "    BS = 10 if archname in ['tf_efficientnet_l2_ns'] else 16\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BS, num_workers=2, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        res = [model(img.to('cuda')).cpu().numpy() for img in train_dataloader]\n",
    "    res = np.concatenate(res, 0)\n",
    "    EMB_TEST[arch] = res\n",
    "\n",
    "    print(arch, 'imge size:', sz, 'Hflip:', doflip, ',Done in:', int(time.time() - starttime), 's')\n",
    "\n",
    "    del model, res\n",
    "    torch.cuda.empty_cache()  # PyTorch thing to clean RAM\n",
    "    gc.collect()\n",
    "\n",
    "print(time.time())\n",
    "len(EMB_TEST), EMB_TEST.keys()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:19:22.887126Z",
     "iopub.execute_input": "2022-12-11T20:19:22.887514Z",
     "iopub.status.idle": "2022-12-11T20:21:34.511226Z",
     "shell.execute_reply.started": "2022-12-11T20:19:22.887479Z",
     "shell.execute_reply": "2022-12-11T20:21:34.510145Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "tf_efficientnet_l2_ns_hflip_384 imge size: 384 Hflip: True ,Done in: 38 s\ndeit_base_distilled_patch16_384_hflip_384 imge size: 384 Hflip: True ,Done in: 7 s\nig_resnext101_32x48d_hflip_384 imge size: 384 Hflip: True ,Done in: 56 s\ntf_efficientnet_l2_ns_512 imge size: 512 Hflip: False ,Done in: 28 s\n1670790094.502298\n",
     "output_type": "stream"
    },
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(20,\n dict_keys(['deit_base_distilled_patch16_384', 'fbnetc_100', 'ig_resnext101_32x8d', 'ig_resnext101_32x48d', 'repvgg_b0', 'resnetv2_152x4_bitm', 'rexnet_200', 'resnest269e', 'swsl_resnext101_32x8d', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8_ap', 'tf_efficientnet_l2_ns_475', 'vit_base_patch16_384', 'vit_large_patch16_384', 'vit_large_r50_s32_384', 'tf_efficientnet_l2_ns_hflip_384', 'deit_base_distilled_patch16_384_hflip_384', 'ig_resnext101_32x48d_hflip_384', 'tf_efficientnet_l2_ns_512']))"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading TRAINSET extracted features (must be offline for Kaggle competitions)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "EMB_TRAIN = joblib.load('../input/petfinderdata/train-embeddings-direct-1.joblib')\n",
    "gc.collect()\n",
    "\n",
    "resclip = joblib.load('../input/openai-clip/train-embeddings-openai-clip-1.joblib')\n",
    "for m in resclip.keys():\n",
    "    EMB_TRAIN[m] = resclip[m]\n",
    "del resclip\n",
    "gc.collect()\n",
    "\n",
    "hflipmodels = joblib.load('../input/petfinder-extracted-pretrained-1/extracted-pretrained-1.joblib')\n",
    "for col in names_hflip_crop:\n",
    "    EMB_TRAIN[col] = hflipmodels[col]\n",
    "del hflipmodels\n",
    "gc.collect()\n",
    "\n",
    "print(len(EMB_TRAIN))\n",
    "print(EMB_TRAIN.keys())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:21:34.516138Z",
     "iopub.execute_input": "2022-12-11T20:21:34.516703Z",
     "iopub.status.idle": "2022-12-11T20:22:21.622313Z",
     "shell.execute_reply.started": "2022-12-11T20:21:34.516661Z",
     "shell.execute_reply": "2022-12-11T20:22:21.620458Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "58\ndict_keys(['adv_inception_v3', 'cait_xs24_384', 'cspdarknet53', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'dla34', 'dm_nfnet_f2', 'dpn68', 'ese_vovnet19b_dw', 'fbnetc_100', 'hrnet_w18', 'hrnet_w30', 'ig_resnext101_32x8d', 'ig_resnext101_32x48d', 'mixnet_m', 'nfnet_l0', 'pit_ti_distilled_224', 'repvgg_b0', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet34d', 'resnetv2_101x1_bitm', 'resnetv2_152x4_bitm', 'resnetv2_50x1_bitm', 'rexnet_130', 'rexnet_200', 'seresnet50', 'seresnet152d', 'ssl_resnext50_32x4d', 'swin_base_patch4_window7_224_in22k', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b8_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnetv2_l_in21ft1k', 'tf_efficientnet_l2_ns', 'tf_mixnet_s', 'twins_pcpvt_small', 'vit_base_patch16_384', 'vit_base_resnet50_384', 'vit_large_patch16_224', 'vit_large_patch16_384', 'vit_large_r50_s32_384', 'xception71', 'clip_RN50', 'clip_RN101', 'clip_RN50x4', 'clip_RN50x16', 'clip_ViT-B-16', 'clip_ViT-B-32', 'tf_efficientnet_l2_ns_hflip_384', 'deit_base_distilled_patch16_384_hflip_384', 'ig_resnext101_32x48d_hflip_384', 'tf_efficientnet_l2_ns_512'])\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display Feature shapes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "for m in EMB_TEST.keys():\n",
    "    print(EMB_TRAIN[m].shape, EMB_TEST[m].shape, m)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:22:21.623639Z",
     "iopub.execute_input": "2022-12-11T20:22:21.624019Z",
     "iopub.status.idle": "2022-12-11T20:22:21.629897Z",
     "shell.execute_reply.started": "2022-12-11T20:22:21.623981Z",
     "shell.execute_reply": "2022-12-11T20:22:21.628967Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "(9912, 1000) (40, 1000) deit_base_distilled_patch16_384\n(9912, 1000) (40, 1000) fbnetc_100\n(9912, 1000) (40, 1000) ig_resnext101_32x8d\n(9912, 1000) (40, 1000) ig_resnext101_32x48d\n(9912, 1000) (40, 1000) repvgg_b0\n(9912, 1000) (40, 1000) resnetv2_152x4_bitm\n(9912, 1000) (40, 1000) rexnet_200\n(9912, 1000) (40, 1000) resnest269e\n(9912, 1000) (40, 1000) swsl_resnext101_32x8d\n(9912, 1000) (40, 1000) tf_efficientnet_b6_ns\n(9912, 1000) (40, 1000) tf_efficientnet_b7_ns\n(9912, 1000) (40, 1000) tf_efficientnet_b8_ap\n(9912, 1000) (40, 1000) tf_efficientnet_l2_ns_475\n(9912, 1000) (40, 1000) vit_base_patch16_384\n(9912, 1000) (40, 1000) vit_large_patch16_384\n(9912, 1000) (40, 1000) vit_large_r50_s32_384\n(9912, 1000) (40, 1000) tf_efficientnet_l2_ns_hflip_384\n(9912, 1000) (40, 1000) deit_base_distilled_patch16_384_hflip_384\n(9912, 1000) (40, 1000) ig_resnext101_32x48d_hflip_384\n(9912, 1000) (40, 1000) tf_efficientnet_l2_ns_512\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "names0 = [\n",
    "\n",
    "    'deit_base_distilled_patch16_384',\n",
    "    'ig_resnext101_32x48d',\n",
    "    'repvgg_b0',\n",
    "    'resnetv2_152x4_bitm',\n",
    "    'swsl_resnext101_32x8d',\n",
    "    'tf_efficientnet_l2_ns_475',\n",
    "    'vit_base_patch16_384',\n",
    "    'vit_large_r50_s32_384'\n",
    "]\n",
    "\n",
    "names1 = [\n",
    "\n",
    "    'fbnetc_100',\n",
    "    'ig_resnext101_32x8d',\n",
    "    'rexnet_200',\n",
    "    'resnest269e',\n",
    "    'tf_efficientnet_b6_ns',\n",
    "    'tf_efficientnet_b8_ap',\n",
    "    'tf_efficientnet_b7_ns',\n",
    "    'vit_large_patch16_384'\n",
    "]\n",
    "\n",
    "names2 = [\n",
    "    'tf_efficientnet_l2_ns_hflip_384',\n",
    "    'deit_base_distilled_patch16_384_hflip_384',\n",
    "    'ig_resnext101_32x48d_hflip_384',\n",
    "    'tf_efficientnet_l2_ns_512',\n",
    "    'ig_resnext101_32x48d',\n",
    "    'vit_large_r50_s32_384'\n",
    "]\n",
    "\n",
    "names = np.unique(names0 + names1 + names2)\n",
    "len(names), names"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:22:21.631658Z",
     "iopub.execute_input": "2022-12-11T20:22:21.632714Z",
     "iopub.status.idle": "2022-12-11T20:22:21.647010Z",
     "shell.execute_reply.started": "2022-12-11T20:22:21.632664Z",
     "shell.execute_reply": "2022-12-11T20:22:21.646025Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "execution_count": 16,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(20,\n array(['deit_base_distilled_patch16_384',\n        'deit_base_distilled_patch16_384_hflip_384', 'fbnetc_100',\n        'ig_resnext101_32x48d', 'ig_resnext101_32x48d_hflip_384',\n        'ig_resnext101_32x8d', 'repvgg_b0', 'resnest269e',\n        'resnetv2_152x4_bitm', 'rexnet_200', 'swsl_resnext101_32x8d',\n        'tf_efficientnet_b6_ns', 'tf_efficientnet_b7_ns',\n        'tf_efficientnet_b8_ap', 'tf_efficientnet_l2_ns_475',\n        'tf_efficientnet_l2_ns_512', 'tf_efficientnet_l2_ns_hflip_384',\n        'vit_base_patch16_384', 'vit_large_patch16_384',\n        'vit_large_r50_s32_384'], dtype='<U41'))"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean memory of offline TRAINSET features which are not going to be used"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "feats = list(EMB_TRAIN.keys())\n",
    "for n in feats:\n",
    "    if n not in names:\n",
    "        del EMB_TRAIN[n]\n",
    "        gc.collect()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:22:21.650323Z",
     "iopub.execute_input": "2022-12-11T20:22:21.650806Z",
     "iopub.status.idle": "2022-12-11T20:22:26.807093Z",
     "shell.execute_reply.started": "2022-12-11T20:22:21.650780Z",
     "shell.execute_reply": "2022-12-11T20:22:26.806120Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GPU accelerated SVR using cuML"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from cuml.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def fit_gpu_svr(TRAIN, TEST, kfoldcol='fold0'):\n",
    "    ypredtrain_ = np.zeros(train.shape[0])\n",
    "    ypredtest_ = np.zeros(test.shape[0])\n",
    "\n",
    "    for fold in range(train[kfoldcol].max() + 1):\n",
    "        ind_train = train[kfoldcol] != fold\n",
    "        ind_valid = train[kfoldcol] == fold\n",
    "\n",
    "        model = SVR(C=30.0, kernel='rbf', degree=3, max_iter=4000, output_type='numpy')\n",
    "        model.fit(TRAIN[ind_train], train.Pawpularity[ind_train].clip(1, 85))\n",
    "\n",
    "        ypredtrain_[ind_valid] = np.clip(model.predict(TRAIN[ind_valid]), 1, 100)\n",
    "        ypredtest_ += np.clip(model.predict(TEST), 1, 100)\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    ypredtest_ /= (train[kfoldcol].max() + 1)\n",
    "\n",
    "    return ypredtrain_, ypredtest_\n",
    "\n",
    "\n",
    "def rmse(ytrue, ypred):\n",
    "    return np.sqrt(np.mean((ytrue - ypred) ** 2))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:22:26.808659Z",
     "iopub.execute_input": "2022-12-11T20:22:26.809033Z",
     "iopub.status.idle": "2022-12-11T20:22:26.818537Z",
     "shell.execute_reply.started": "2022-12-11T20:22:26.808995Z",
     "shell.execute_reply": "2022-12-11T20:22:26.817542Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVR for each architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "for col in names:\n",
    "    TRAIN = EMB_TRAIN[col].copy()\n",
    "    TEST = EMB_TEST[col].copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.vstack((TRAIN, TEST)))\n",
    "    TRAIN = scaler.transform(TRAIN)\n",
    "    TEST = scaler.transform(TEST)\n",
    "\n",
    "    ypredtrain, ypredtest = fit_gpu_svr(TRAIN, TEST, 'fold0')\n",
    "    print(rmse(train.Pawpularity, ypredtrain), col)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:22:26.820367Z",
     "iopub.execute_input": "2022-12-11T20:22:26.821260Z",
     "iopub.status.idle": "2022-12-11T20:27:28.607736Z",
     "shell.execute_reply.started": "2022-12-11T20:22:26.821220Z",
     "shell.execute_reply": "2022-12-11T20:27:28.606667Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": "17.712809941265807 deit_base_distilled_patch16_384\n17.704078387405332 deit_base_distilled_patch16_384_hflip_384\n18.48424837093278 fbnetc_100\n17.755805285329178 ig_resnext101_32x48d\n17.780893496477624 ig_resnext101_32x48d_hflip_384\n17.958093335328353 ig_resnext101_32x8d\n18.253444602567463 repvgg_b0\n18.0009617924418 resnest269e\n18.13575249613704 resnetv2_152x4_bitm\n17.973611293382902 rexnet_200\n18.015502770431883 swsl_resnext101_32x8d\n17.744341478237462 tf_efficientnet_b6_ns\n17.742343658651897 tf_efficientnet_b7_ns\n17.750993426678342 tf_efficientnet_b8_ap\n17.619187153498366 tf_efficientnet_l2_ns_475\n17.61844972450698 tf_efficientnet_l2_ns_512\n17.689217431423767 tf_efficientnet_l2_ns_hflip_384\n17.92158811171319 vit_base_patch16_384\n18.01499760636718 vit_large_patch16_384\n18.00659110030843 vit_large_r50_s32_384\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### As we can see above, SVR RMSE ranges from 17.56 to 18.52"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea is to stack architectures features together"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVR A (names0)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print('Concatenating:', names0)\n",
    "\n",
    "TRAIN = np.concatenate([EMB_TRAIN[k] for k in names0], 1)\n",
    "TEST = np.concatenate([EMB_TEST[k] for k in names0], 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack((TRAIN, TEST)))\n",
    "gc.collect()\n",
    "\n",
    "TRAIN = scaler.transform(TRAIN)\n",
    "TEST = scaler.transform(TEST)\n",
    "gc.collect()\n",
    "\n",
    "# Check the output shape\n",
    "print(TRAIN.shape, TEST.shape)\n",
    "\n",
    "ypredtrainA, ypredtestA = fit_gpu_svr(TRAIN, TEST, 'fold0')\n",
    "print(rmse(train.Pawpularity, ypredtrainA))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:27:28.610532Z",
     "iopub.execute_input": "2022-12-11T20:27:28.610985Z",
     "iopub.status.idle": "2022-12-11T20:28:07.527741Z",
     "shell.execute_reply.started": "2022-12-11T20:27:28.610956Z",
     "shell.execute_reply": "2022-12-11T20:28:07.526702Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": "Concatenating: ['deit_base_distilled_patch16_384', 'ig_resnext101_32x48d', 'repvgg_b0', 'resnetv2_152x4_bitm', 'swsl_resnext101_32x8d', 'tf_efficientnet_l2_ns_475', 'vit_base_patch16_384', 'vit_large_r50_s32_384']\n(9912, 8000) (40, 8000)\n17.231539198315136\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "del TRAIN, TEST\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:28:07.529082Z",
     "iopub.execute_input": "2022-12-11T20:28:07.529996Z",
     "iopub.status.idle": "2022-12-11T20:28:07.671805Z",
     "shell.execute_reply.started": "2022-12-11T20:28:07.529956Z",
     "shell.execute_reply": "2022-12-11T20:28:07.670539Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using the multiplier of 1.032 boosts RMSE score, probably because SVR uses MSE based optimization. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print('RMSE:', rmse(train.Pawpularity, 1.032 * ypredtrainA))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:28:07.673530Z",
     "iopub.execute_input": "2022-12-11T20:28:07.673954Z",
     "iopub.status.idle": "2022-12-11T20:28:07.682345Z",
     "shell.execute_reply.started": "2022-12-11T20:28:07.673919Z",
     "shell.execute_reply": "2022-12-11T20:28:07.681403Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": "RMSE: 17.224564776006655\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVR B (names1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print('Concatenating:', names1)\n",
    "\n",
    "TRAIN = np.concatenate([EMB_TRAIN[k] for k in names1], 1)\n",
    "TEST = np.concatenate([EMB_TEST[k] for k in names1], 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack((TRAIN, TEST)))\n",
    "gc.collect()\n",
    "\n",
    "TRAIN = scaler.transform(TRAIN)\n",
    "TEST = scaler.transform(TEST)\n",
    "gc.collect()\n",
    "\n",
    "print(TRAIN.shape, TEST.shape)\n",
    "\n",
    "ypredtrainB, ypredtestB = fit_gpu_svr(TRAIN, TEST, 'fold0')\n",
    "print('RMSE:', rmse(train.Pawpularity, ypredtrainB))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:28:07.683807Z",
     "iopub.execute_input": "2022-12-11T20:28:07.684783Z",
     "iopub.status.idle": "2022-12-11T20:28:45.575498Z",
     "shell.execute_reply.started": "2022-12-11T20:28:07.684742Z",
     "shell.execute_reply": "2022-12-11T20:28:45.574363Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": "Concatenating: ['fbnetc_100', 'ig_resnext101_32x8d', 'rexnet_200', 'resnest269e', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b8_ap', 'tf_efficientnet_b7_ns', 'vit_large_patch16_384']\n(9912, 8000) (40, 8000)\nRMSE: 17.337306863761512\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "del TRAIN, TEST\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:28:45.576882Z",
     "iopub.execute_input": "2022-12-11T20:28:45.577721Z",
     "iopub.status.idle": "2022-12-11T20:28:45.726200Z",
     "shell.execute_reply.started": "2022-12-11T20:28:45.577683Z",
     "shell.execute_reply": "2022-12-11T20:28:45.724792Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVR C (names2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print('Concatenating:', names2)\n",
    "\n",
    "TRAIN = np.concatenate([EMB_TRAIN[k] for k in names2], 1)\n",
    "TEST = np.concatenate([EMB_TEST[k] for k in names2], 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.vstack((TRAIN, TEST)))\n",
    "gc.collect()\n",
    "\n",
    "TRAIN = scaler.transform(TRAIN)\n",
    "TEST = scaler.transform(TEST)\n",
    "gc.collect()\n",
    "\n",
    "print(TRAIN.shape, TEST.shape)\n",
    "\n",
    "ypredtrainC, ypredtestC = fit_gpu_svr(TRAIN, TEST, 'fold0')\n",
    "print('RMSE:', rmse(train.Pawpularity, ypredtrainC))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:28:45.728148Z",
     "iopub.execute_input": "2022-12-11T20:28:45.728556Z",
     "iopub.status.idle": "2022-12-11T20:29:17.557270Z",
     "shell.execute_reply.started": "2022-12-11T20:28:45.728519Z",
     "shell.execute_reply": "2022-12-11T20:29:17.556252Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": "Concatenating: ['tf_efficientnet_l2_ns_hflip_384', 'deit_base_distilled_patch16_384_hflip_384', 'ig_resnext101_32x48d_hflip_384', 'tf_efficientnet_l2_ns_512', 'ig_resnext101_32x48d', 'vit_large_r50_s32_384']\n(9912, 6000) (40, 6000)\nRMSE: 17.263647505975836\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Free RAM and GPU memory\n",
    "del TRAIN, TEST\n",
    "del EMB_TRAIN, EMB_TEST\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()  # PyTorch thing to free GPU memory\n",
    "gc.collect()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:29:17.559508Z",
     "iopub.execute_input": "2022-12-11T20:29:17.560162Z",
     "iopub.status.idle": "2022-12-11T20:29:17.860475Z",
     "shell.execute_reply.started": "2022-12-11T20:29:17.560125Z",
     "shell.execute_reply": "2022-12-11T20:29:17.858697Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": [
    {
     "execution_count": 26,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run inference using Deep Learning finetuned image models. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "class Config:\n",
    "    model_name = \"swin_large_patch4_window7_224\"\n",
    "    base_dir = \"../input/petfinder-pawpularity-score\"\n",
    "    data_dir = base_dir\n",
    "    model_dir = \"exp\"\n",
    "    output_dir = model_dir\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    model_path = \"swin_large_patch4_window7_224\"\n",
    "    im_size = 384\n",
    "    batch_size = 16\n",
    "\n",
    "\n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_filepaths, targets, transform=None):\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_filepaths[idx]\n",
    "        with open(image_filepath, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image_rgb = image.convert('RGB')\n",
    "        image = np.array(image_rgb)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        image = image / 255\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        target = torch.tensor(target, dtype=torch.float)\n",
    "        return image, target\n",
    "\n",
    "\n",
    "def get_inference_fixed_transforms(mode=0, dim=224):\n",
    "    if mode == 0:  # do not original aspects, colors and angles\n",
    "        return A.Compose([\n",
    "            A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "            A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "        ], p=1.0)\n",
    "    elif mode == 1:\n",
    "        return A.Compose([\n",
    "            A.SmallestMaxSize(max_size=dim + 16, p=1.0),\n",
    "            A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "            A.HorizontalFlip(p=1.0)\n",
    "        ], p=1.0)\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name=Config.model_path,\n",
    "            out_features=1,\n",
    "            inp_channels=3,\n",
    "            pretrained=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=False, in_chans=3, num_classes=1)\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.model(image)\n",
    "        return output\n",
    "\n",
    "\n",
    "def tta_fn(filepaths, model, ttas=[0, 1]):\n",
    "    print('Image Size:', Config.im_size)\n",
    "    model.eval()\n",
    "    tta_preds = []\n",
    "    for tta_mode in ttas:  #range(Config.tta_times):\n",
    "        print(f'tta mode:{tta_mode}')\n",
    "        test_dataset = PetDataset(\n",
    "            image_filepaths=filepaths,\n",
    "            targets=np.zeros(len(filepaths)),\n",
    "            transform=get_inference_fixed_transforms(tta_mode, dim=Config.im_size)\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=Config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        #stream = tqdm(test_loader)\n",
    "        tta_pred = []\n",
    "        for images, target in test_loader:  #enumerate(stream, start = 1):\n",
    "            images = images.to(device, non_blocking=True).float()\n",
    "            target = target.to(device, non_blocking=True).float().view(-1, 1)\n",
    "            with torch.no_grad():\n",
    "                output = model(images)\n",
    "\n",
    "            pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n",
    "            tta_pred.extend(pred)\n",
    "        tta_preds.append(np.array(tta_pred))\n",
    "\n",
    "    fold_preds = tta_preds[0]\n",
    "    for n in range(1, len(tta_preds)):\n",
    "        fold_preds += tta_preds[n]\n",
    "    fold_preds /= len(tta_preds)\n",
    "\n",
    "    del test_loader, test_dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return fold_preds"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:29:17.862358Z",
     "iopub.execute_input": "2022-12-11T20:29:17.863038Z",
     "iopub.status.idle": "2022-12-11T20:29:18.543357Z",
     "shell.execute_reply.started": "2022-12-11T20:29:17.863000Z",
     "shell.execute_reply": "2022-12-11T20:29:18.542445Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# List all test files\n",
    "filepaths = test['path'].values.copy()\n",
    "len(filepaths)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:29:18.544917Z",
     "iopub.execute_input": "2022-12-11T20:29:18.545273Z",
     "iopub.status.idle": "2022-12-11T20:29:18.553624Z",
     "shell.execute_reply.started": "2022-12-11T20:29:18.545235Z",
     "shell.execute_reply": "2022-12-11T20:29:18.552708Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": [
    {
     "execution_count": 28,
     "output_type": "execute_result",
     "data": {
      "text/plain": "40"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "% % time\n",
    "\n",
    "class Config:\n",
    "    model_dir = \"exp53\"\n",
    "    output_dir = \"exp53\"\n",
    "    model_name = \"swin_large_patch4_window7_224\"\n",
    "    im_size = 224\n",
    "    model_path = model_name\n",
    "    base_dir = \"../input/petfinder-pawpularity-score\"\n",
    "    data_dir = base_dir\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    batch_size = 16\n",
    "\n",
    "\n",
    "test_preds = []\n",
    "test_preds_model = []\n",
    "modelfiles = glob('../input/petfinder-' + Config.model_dir + '/*.pth')\n",
    "for mi, model_path in enumerate(modelfiles):\n",
    "    print(f'inference: {model_path}')\n",
    "    test_preds_fold = []\n",
    "    model = PetNet(\n",
    "        model_name=Config.model_path,\n",
    "        out_features=1,\n",
    "        inp_channels=3,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model = model.float()\n",
    "    model.eval()\n",
    "    test_preds_fold = tta_fn(filepaths, model, [1])\n",
    "    test_preds_model.append(test_preds_fold)\n",
    "\n",
    "oof53 = pd.read_csv('../input/petfinder-' + Config.model_dir + '/oof_tta.csv')\n",
    "final_predictions53 = np.mean(np.array(test_preds_model), axis=0)\n",
    "final_predictions53"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:29:18.555521Z",
     "iopub.execute_input": "2022-12-11T20:29:18.556348Z",
     "iopub.status.idle": "2022-12-11T20:31:15.372501Z",
     "shell.execute_reply.started": "2022-12-11T20:29:18.556309Z",
     "shell.execute_reply": "2022-12-11T20:31:15.371407Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": "inference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold5_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold9_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold2_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold1_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold0_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold6_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold4_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold7_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold8_half.pth\nImage Size: 224\ntta mode:1\ninference: ../input/petfinder-exp53/swin_large_patch4_window7_224_fold3_half.pth\nImage Size: 224\ntta mode:1\nCPU times: user 47.4 s, sys: 5.85 s, total: 53.3 s\nWall time: 1min 56s\n",
     "output_type": "stream"
    },
    {
     "execution_count": 29,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([41.54221554, 42.02376919, 42.01871738, 42.70148811, 41.79610214,\n       42.11279564, 42.43319626, 41.76821747, 41.54221554, 42.02376919,\n       42.01871738, 42.70148811, 41.79610214, 42.11279564, 42.43319626,\n       41.76821747, 41.54221554, 42.02376919, 42.01871738, 42.70148811,\n       41.79610214, 42.11279564, 42.43319626, 41.76821747, 41.54221554,\n       42.02376919, 42.01871738, 42.70148811, 41.79610214, 42.11279564,\n       42.43319626, 41.76821747, 41.54221344, 42.02376728, 42.01871548,\n       42.70148315, 41.79609795, 42.11279297, 42.43319435, 41.76821861])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "% % time\n",
    "\n",
    "class Config:\n",
    "    model_dir = \"exp55\"\n",
    "    output_dir = \"exp55\"\n",
    "    model_name = \"beit_large_patch16_224\"\n",
    "    im_size = 224\n",
    "    model_path = model_name\n",
    "    base_dir = \"../input/petfinder-pawpularity-score\"\n",
    "    data_dir = base_dir\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    batch_size = 16\n",
    "\n",
    "\n",
    "test_preds = []\n",
    "test_preds_model = []\n",
    "modelfiles = glob('../input/petfinder-' + Config.model_dir + '/*.pth')\n",
    "for mi, model_path in enumerate(modelfiles):\n",
    "    print(f'inference: {model_path}')\n",
    "    test_preds_fold = []\n",
    "    model = PetNet(\n",
    "        model_name=Config.model_path,\n",
    "        out_features=1,\n",
    "        inp_channels=3,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model = model.float()\n",
    "    model.eval()\n",
    "    test_preds_fold = tta_fn(filepaths, model, [0])\n",
    "    test_preds_model.append(test_preds_fold)\n",
    "\n",
    "oof55 = pd.read_csv('../input/petfinder-' + Config.model_dir + '/oof_tta.csv')\n",
    "final_predictions55 = np.mean(np.array(test_preds_model), axis=0)\n",
    "final_predictions55"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:31:15.374171Z",
     "iopub.execute_input": "2022-12-11T20:31:15.374801Z",
     "iopub.status.idle": "2022-12-11T20:34:02.277725Z",
     "shell.execute_reply.started": "2022-12-11T20:31:15.374765Z",
     "shell.execute_reply": "2022-12-11T20:34:02.276670Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": "inference: ../input/petfinder-exp55/beit_large_patch16_224_fold4_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold7_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold1_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold0_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold5_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold9_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold6_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold2_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold8_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp55/beit_large_patch16_224_fold3_half.pth\nImage Size: 224\ntta mode:0\nCPU times: user 1min 11s, sys: 8.48 s, total: 1min 19s\nWall time: 2min 46s\n",
     "output_type": "stream"
    },
    {
     "execution_count": 30,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([48.3031147 , 48.46970367, 48.34081039, 48.52948532, 48.60842323,\n       48.04617119, 48.40596275, 48.20590172, 48.3031147 , 48.46970367,\n       48.34081039, 48.52948532, 48.60842323, 48.04617119, 48.40596275,\n       48.20590172, 48.3031147 , 48.46970367, 48.34081039, 48.52948532,\n       48.60842323, 48.04617119, 48.40596275, 48.20590172, 48.3031147 ,\n       48.46970367, 48.34081039, 48.52948532, 48.60842323, 48.04617119,\n       48.40596275, 48.20590172, 48.30311203, 48.46970329, 48.34081154,\n       48.5294899 , 48.60842361, 48.04617386, 48.40596008, 48.20590057])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "% % time\n",
    "\n",
    "class Config:\n",
    "    model_dir = \"exp66\"\n",
    "    output_dir = \"exp66\"\n",
    "    model_name = \"swin_large_patch4_window12_384_in22k\"\n",
    "    im_size = 384\n",
    "    model_path = model_name\n",
    "    base_dir = \"../input/petfinder-pawpularity-score\"\n",
    "    data_dir = base_dir\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    batch_size = 16\n",
    "\n",
    "\n",
    "test_preds = []\n",
    "test_preds_model = []\n",
    "modelfiles = glob('../input/petfinder-' + Config.model_dir + '/*.pth')\n",
    "for mi, model_path in enumerate(modelfiles):\n",
    "    print(f'inference: {model_path}')\n",
    "    test_preds_fold = []\n",
    "    model = PetNet(\n",
    "        model_name=Config.model_path,\n",
    "        out_features=1,\n",
    "        inp_channels=3,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model = model.float()\n",
    "    model.eval()\n",
    "    test_preds_fold = tta_fn(filepaths, model, [0])\n",
    "    test_preds_model.append(test_preds_fold)\n",
    "\n",
    "oof66 = pd.read_csv('../input/petfinder-' + Config.model_dir + '/oof_tta.csv')\n",
    "final_predictions66 = np.mean(np.array(test_preds_model), axis=0)\n",
    "final_predictions66"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:34:02.279455Z",
     "iopub.execute_input": "2022-12-11T20:34:02.280071Z",
     "iopub.status.idle": "2022-12-11T20:36:11.536209Z",
     "shell.execute_reply.started": "2022-12-11T20:34:02.280035Z",
     "shell.execute_reply": "2022-12-11T20:36:11.535096Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": "inference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold5_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold2_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold8_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold7_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold1_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold3_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold0_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold6_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold9_half.pth\nImage Size: 384\ntta mode:0\ninference: ../input/petfinder-exp66/swin_large_patch4_window12_384_in22k_fold4_half.pth\nImage Size: 384\ntta mode:0\nCPU times: user 58 s, sys: 6.36 s, total: 1min 4s\nWall time: 2min 9s\n",
     "output_type": "stream"
    },
    {
     "execution_count": 31,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([44.19167061, 43.99319916, 44.02210159, 44.39536629, 43.86056747,\n       44.02656174, 44.71376114, 44.19404564, 44.19167061, 43.99319916,\n       44.02210159, 44.39536629, 43.86056747, 44.02656174, 44.71376114,\n       44.19404564, 44.19167061, 43.99319916, 44.02210159, 44.39536629,\n       43.86056747, 44.02656174, 44.71376114, 44.19404564, 44.19167061,\n       43.99319916, 44.02210159, 44.39536629, 43.86056747, 44.02656174,\n       44.71376114, 44.19404564, 44.19167213, 43.99320107, 44.02210236,\n       44.39536781, 43.86056786, 44.02656097, 44.71376114, 44.19404488])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "% % time\n",
    "\n",
    "class Config:\n",
    "    model_dir = \"exp77\"\n",
    "    output_dir = \"exp77\"\n",
    "    model_name = \"beit_large_patch16_224\"\n",
    "    im_size = 224\n",
    "    model_path = model_name\n",
    "    base_dir = \"../input/petfinder-pawpularity-score\"\n",
    "    data_dir = base_dir\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    batch_size = 16\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name=Config.model_path,\n",
    "            out_features=1,\n",
    "            inp_channels=3,\n",
    "            pretrained=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        NC = 1000\n",
    "        self.model = timm.create_model(model_name, pretrained=False)\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "        self.head = nn.Linear(NC, 1)\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.model(image)\n",
    "        output = self.dropout(output)\n",
    "        output = self.head(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "test_preds = []\n",
    "test_preds_model = []\n",
    "modelfiles = glob('../input/petfinder-' + Config.model_dir + '/*.pth')\n",
    "for mi, model_path in enumerate(modelfiles):\n",
    "    print(f'inference: {model_path}')\n",
    "    test_preds_fold = []\n",
    "    model = PetNet(\n",
    "        model_name=Config.model_path,\n",
    "        out_features=1,\n",
    "        inp_channels=3,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model = model.float()\n",
    "    model.eval()\n",
    "    test_preds_fold = tta_fn(filepaths, model, [0])\n",
    "    test_preds_model.append(test_preds_fold)\n",
    "\n",
    "oof77 = pd.read_csv('../input/petfinder-' + Config.model_dir + '/oof_tta.csv')\n",
    "final_predictions77 = np.mean(np.array(test_preds_model), axis=0)\n",
    "final_predictions77"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:36:11.537854Z",
     "iopub.execute_input": "2022-12-11T20:36:11.538517Z",
     "iopub.status.idle": "2022-12-11T20:38:54.249077Z",
     "shell.execute_reply.started": "2022-12-11T20:36:11.538479Z",
     "shell.execute_reply": "2022-12-11T20:38:54.248035Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": "inference: ../input/petfinder-exp77/beit_large_patch16_224_fold4_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold7_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold1_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold0_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold5_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold9_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold6_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold2_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold8_half.pth\nImage Size: 224\ntta mode:0\ninference: ../input/petfinder-exp77/beit_large_patch16_224_fold3_half.pth\nImage Size: 224\ntta mode:0\nCPU times: user 1min 11s, sys: 9.22 s, total: 1min 20s\nWall time: 2min 42s\n",
     "output_type": "stream"
    },
    {
     "execution_count": 32,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([44.79068413, 45.35668354, 45.35797005, 45.44356155, 46.04086342,\n       45.89144001, 46.58387165, 45.84169559, 44.79068413, 45.35668354,\n       45.35797005, 45.44356155, 46.04086342, 45.89144001, 46.58387165,\n       45.84169559, 44.79068413, 45.35668354, 45.35797005, 45.44356155,\n       46.04086342, 45.89144001, 46.58387165, 45.84169559, 44.79068413,\n       45.35668354, 45.35797005, 45.44356155, 46.04086342, 45.89144001,\n       46.58387165, 45.84169559, 44.79068184, 45.35668907, 45.35796356,\n       45.44356709, 46.0408659 , 45.89143333, 46.58385677, 45.8416872 ])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "% % time\n",
    "\n",
    "class Config:\n",
    "    model_dir = \"exp82\"\n",
    "    output_dir = \"exp82\"\n",
    "    model_name = \"tf_efficientnet_b6_ns\"\n",
    "    im_size = 528\n",
    "    model_path = model_name\n",
    "    base_dir = \"../input/petfinder-pawpularity-score\"\n",
    "    data_dir = base_dir\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    batch_size = 16\n",
    "\n",
    "\n",
    "class PetNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name=Config.model_path,\n",
    "            out_features=1,\n",
    "            inp_channels=3,\n",
    "            pretrained=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        NC = 1000\n",
    "        self.model = timm.create_model(model_name, pretrained=False)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.head = nn.Linear(NC, out_features)\n",
    "\n",
    "    def forward(self, image):\n",
    "        output = self.model(image)\n",
    "        output = self.dropout(output)\n",
    "        output = self.head(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "test_preds = []\n",
    "test_preds_model = []\n",
    "modelfiles = glob('../input/petfinder-' + Config.model_dir + '/*.pth')\n",
    "for mi, model_path in enumerate(modelfiles):\n",
    "    print(f'inference: {model_path}')\n",
    "    test_preds_fold = []\n",
    "    model = PetNet(\n",
    "        model_name=Config.model_path,\n",
    "        out_features=1,\n",
    "        inp_channels=3,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model = model.float()\n",
    "    model.eval()\n",
    "    test_preds_fold = tta_fn(filepaths, model, [0])\n",
    "    test_preds_model.append(test_preds_fold)\n",
    "\n",
    "oof82 = pd.read_csv('../input/petfinder-' + Config.model_dir + '/oof_tta.csv')\n",
    "final_predictions82 = np.mean(np.array(test_preds_model), axis=0)\n",
    "final_predictions82"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:38:54.251446Z",
     "iopub.execute_input": "2022-12-11T20:38:54.252307Z",
     "iopub.status.idle": "2022-12-11T20:39:40.650303Z",
     "shell.execute_reply.started": "2022-12-11T20:38:54.252269Z",
     "shell.execute_reply": "2022-12-11T20:39:40.648963Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": "inference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold3_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold7_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold6_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold5_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold8_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold0_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold9_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold1_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold4_half.pth\nImage Size: 528\ntta mode:0\ninference: ../input/petfinder-exp82/tf_efficientnet_b6_ns_fold2_half.pth\nImage Size: 528\ntta mode:0\nCPU times: user 23.5 s, sys: 4.46 s, total: 28 s\nWall time: 46.4 s\n",
     "output_type": "stream"
    },
    {
     "execution_count": 33,
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([37.48838024, 37.35873871, 36.76660423, 36.27986965, 37.43988914,\n       37.87288513, 36.98650017, 37.08287888, 37.48838024, 37.35873871,\n       36.76660423, 36.27986965, 37.43988914, 37.87288513, 36.98650017,\n       37.08287888, 37.48838024, 37.35873871, 36.76660423, 36.27986965,\n       37.43988914, 37.87288513, 36.98650017, 37.08287888, 37.48838024,\n       37.35873871, 36.76660423, 36.27986965, 37.43988914, 37.87288513,\n       36.98650017, 37.08287888, 37.48838024, 37.35873871, 36.76660423,\n       36.27986965, 37.43988914, 37.87288513, 36.98650017, 37.08287888])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the weights\n",
    "\n",
    "a = 3\n",
    "b = 4\n",
    "c = 3\n",
    "d = 4\n",
    "e = 2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:39:40.652211Z",
     "iopub.execute_input": "2022-12-11T20:39:40.652953Z",
     "iopub.status.idle": "2022-12-11T20:39:40.658432Z",
     "shell.execute_reply.started": "2022-12-11T20:39:40.652912Z",
     "shell.execute_reply": "2022-12-11T20:39:40.657522Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weighted average image models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "oof = oof53.copy()\n",
    "oof['pred'] = (\n",
    "                      a * oof53['pred'] +\n",
    "                      b * oof55['pred'] +\n",
    "                      c * oof66['pred'] +\n",
    "                      d * oof77['pred'] +\n",
    "                      e * oof82['pred']\n",
    "              ) / (a + b + c + d + e)\n",
    "\n",
    "final_train_predictions = train.merge(oof, on='Id', how='left')['pred'].values.copy()\n",
    "\n",
    "rmse(train.Pawpularity.values, final_train_predictions)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:39:40.660162Z",
     "iopub.execute_input": "2022-12-11T20:39:40.660591Z",
     "iopub.status.idle": "2022-12-11T20:39:40.717378Z",
     "shell.execute_reply.started": "2022-12-11T20:39:40.660551Z",
     "shell.execute_reply": "2022-12-11T20:39:40.716566Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "execution_count": 35,
     "output_type": "execute_result",
     "data": {
      "text/plain": "17.02954258971035"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "final_test_predictions = (\n",
    "                                 a * final_predictions53 +\n",
    "                                 b * final_predictions55 +\n",
    "                                 c * final_predictions66 +\n",
    "                                 d * final_predictions77 +\n",
    "                                 e * final_predictions82\n",
    "                         ) / (a + b + c + d + e)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:39:40.718689Z",
     "iopub.execute_input": "2022-12-11T20:39:40.719026Z",
     "iopub.status.idle": "2022-12-11T20:39:40.724663Z",
     "shell.execute_reply.started": "2022-12-11T20:39:40.718992Z",
     "shell.execute_reply": "2022-12-11T20:39:40.723534Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# SciPy optimize provides functions for minimizing (or maximizing) objective functions, possibly subject to constraints.\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def min_func(K):\n",
    "    ypredtrain = K[0] * ypredtrainA + K[1] * ypredtrainB + K[2] * ypredtrainC + K[3] * final_train_predictions\n",
    "    return rmse(train.Pawpularity, ypredtrain)\n",
    "\n",
    "\n",
    "res = minimize(min_func, [1 / 4] * 4, method='Nelder-Mead', tol=1e-6)\n",
    "K = res.x\n",
    "res"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:39:40.726177Z",
     "iopub.execute_input": "2022-12-11T20:39:40.726818Z",
     "iopub.status.idle": "2022-12-11T20:39:40.868446Z",
     "shell.execute_reply.started": "2022-12-11T20:39:40.726782Z",
     "shell.execute_reply": "2022-12-11T20:39:40.867422Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": [
    {
     "execution_count": 37,
     "output_type": "execute_result",
     "data": {
      "text/plain": " final_simplex: (array([[0.18395402, 0.08305837, 0.19805342, 0.55311892],\n       [0.18395461, 0.08305828, 0.198053  , 0.55311888],\n       [0.18395426, 0.08305813, 0.19805353, 0.55311878],\n       [0.1839544 , 0.08305926, 0.19805293, 0.55311815],\n       [0.18395469, 0.08305802, 0.19805364, 0.55311845]]), array([16.87297215, 16.87297215, 16.87297215, 16.87297215, 16.87297215]))\n           fun: 16.872972151586403\n       message: 'Optimization terminated successfully.'\n          nfev: 247\n           nit: 140\n        status: 0\n       success: True\n             x: array([0.18395402, 0.08305837, 0.19805342, 0.55311892])"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ypredtrain = K[0] * ypredtrainA + K[1] * ypredtrainB + K[2] * ypredtrainC + K[3] * final_train_predictions\n",
    "\n",
    "test['Pawpularity'] = K[0] * ypredtestA + K[1] * ypredtestB + K[2] * ypredtestC + K[3] * final_test_predictions\n",
    "\n",
    "print('Ensemble weights:', K)\n",
    "print('Final RMSE:', rmse(train.Pawpularity, ypredtrain))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:51:43.848612Z",
     "iopub.execute_input": "2022-12-11T20:51:43.849537Z",
     "iopub.status.idle": "2022-12-11T20:51:43.864617Z",
     "shell.execute_reply.started": "2022-12-11T20:51:43.849477Z",
     "shell.execute_reply": "2022-12-11T20:51:43.861793Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "text": "Ensemble weights: [0.18395402 0.08305837 0.19805342 0.55311892]\nFinal RMSE: 16.872972151586403\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Not used (Competition only)\n",
    "#test.head(8)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:39:40.882516Z",
     "iopub.execute_input": "2022-12-11T20:39:40.883192Z",
     "iopub.status.idle": "2022-12-11T20:39:40.888216Z",
     "shell.execute_reply.started": "2022-12-11T20:39:40.883158Z",
     "shell.execute_reply": "2022-12-11T20:39:40.887057Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Not used (Competition only)\n",
    "#test[['Id','Pawpularity']].to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-11T20:39:40.890252Z",
     "iopub.execute_input": "2022-12-11T20:39:40.890673Z",
     "iopub.status.idle": "2022-12-11T20:39:40.896035Z",
     "shell.execute_reply.started": "2022-12-11T20:39:40.890639Z",
     "shell.execute_reply": "2022-12-11T20:39:40.894966Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": []
  }
 ]
}
